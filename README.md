# IA02 â€“ Classification non linÃ©aire grÃ¢ce Ã  lâ€™IA avancÃ©e

ğŸ“Œ Description du projet

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du cours IA02 Ã  lâ€™UTT.
Lâ€™objectif Ã©tait de dÃ©velopper et comparer des algorithmes dâ€™intelligence artificielle non linÃ©aires appliquÃ©s Ã  deux types de donnÃ©es :

Partie 1 â€“ Vision : Classification dâ€™images avec le dataset CIFAR-10 (60 000 images en 10 classes).

Partie 2 â€“ Signaux : DÃ©tection de chutes Ã  partir de donnÃ©es de capteurs (dataset de signaux multidimensionnels).

# ğŸ§© Partie 1 â€“ Classification dâ€™images (CIFAR-10)

Analyse exploratoire du dataset (rÃ©partition, visualisations).

ImplÃ©mentation et comparaison de :

2 algorithmes de Machine Learning classiques 

3 CNN avec diffÃ©rentes architectures.

1 CNN hybride combinant plusieurs approches.

Ã‰valuation en termes de prÃ©cision et de temps de calcul.

# ğŸ§© Partie 2 â€“ DÃ©tection de chutes

Nous avons choisi le Dataset 2 : Fall Detection.

## Dataset :

757 Ã©chantillons de signaux multidimensionnels reprÃ©sentant la variation du champ Ã©lectromagnÃ©tique.

CollectÃ©s sur 22 participants dans 4 environnements diffÃ©rents.

321 Ã©chantillons correspondent Ã  des chutes.

## Objectif : DÃ©velopper des algorithmes de classification binaires pour distinguer chute / non-chute.

Contraintes dâ€™Ã©valuation :

EntraÃ®nement sur les 22 participants et 4 environnements, puis test sur des signaux nouveaux.

EntraÃ®nement avec uniquement certains environnements/participants, et test sur des participants inconnus dans des environnements nouveaux.

## Travail rÃ©alisÃ© :

Analyse des signaux et prÃ©paration des donnÃ©es.

ImplÃ©mentation de plusieurs algorithmes de classification (DL).

Mise en place de techniques dâ€™augmentation des donnÃ©es pour amÃ©liorer la robustesse.

Comparaison des performances sur donnÃ©es vues et non vues.

## ğŸ“Š MÃ©thodologie

PrÃ©traitement des donnÃ©es (normalisation, segmentation, transformations).

Test de diffÃ©rents modÃ¨les de Deep Learning.

Ajustement des hyperparamÃ¨tres pour chaque modÃ¨le.

Ã‰valuation : exactitude, F1-score, robustesse sur environnements/participants nouveaux.

## ğŸš€ RÃ©sultats attendus

Comparaison dÃ©taillÃ©e des performances des modÃ¨les.

Impact des techniques dâ€™augmentation de donnÃ©es.

Discussion sur les limites et perspectives (gÃ©nÃ©ralisation, surapprentissage, robustesse).

## ğŸ‘¥ Ã‰quipe

Projet rÃ©alisÃ© en binÃ´me dans le cadre du cours IA02 â€“ Printemps 2025

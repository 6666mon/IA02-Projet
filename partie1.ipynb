{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation Dataset CIFAR-10\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train_t, y_train_t), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librairie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66101242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split le data set en train et en validation (pour les CNN)\n",
    "\n",
    "N_train_t = np.shape(x_train_t)[0]\n",
    "N_train = round(0.8*N_train_t) # 80% pour le train et 20% pour la validation\n",
    "x_train,y_train = x_train_t[0:N_train],y_train_t[0:N_train]\n",
    "x_val,y_val = x_train_t[N_train:],y_train_t[N_train:]\n",
    "\n",
    "#Normalisation des images\n",
    "\n",
    "x_train, x_val, x_test = x_train / 255.0, x_val / 255.0, x_test / 255.0\n",
    "\n",
    "plt.figure\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_train[i],cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6327ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo de ML : Decision Tree \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "x_train_flat = x_train_t.reshape((x_train_t.shape[0], -1))\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_flat)\n",
    "x_test_scaled = scaler.transform(x_test_flat)\n",
    "\n",
    "arbre = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "arbre.fit(x_train_scaled, y_train_t.ravel())\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# GridSearch avec validation croisée 3-fold\n",
    "grid_search = GridSearchCV(arbre, param_grid, cv=3)\n",
    "grid_search.fit(x_train_scaled, y_train_t.ravel())\n",
    "\n",
    "y_pred = arbre.predict(x_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='macro')  # Calcul du rappel\n",
    "print(f\"Précision de l'arbre de décision sur CIFAR-10 : {acc:.2f}\")\n",
    "print(f\"Rappel de l'arbre de décision sur CIFAR-10 : {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foret Aleatoire \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entraînement du modèle\n",
    "rf.fit(x_train_scaled, y_train_t.ravel())\n",
    "\n",
    "# Prédiction et évaluation\n",
    "y_pred = rf.predict(x_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='macro')  # Calcul du rappel\n",
    "print(f\"Précision de la forêt aléatoire sur CIFAR-10 : {acc:.2f}\")\n",
    "print(f\"Rappel de la forêt aléatoire sur CIFAR-10 : {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54892af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 CNN aux architectures différentes\n",
    "\n",
    "# Redimensionner les images (28x28 -> 28x28x1) pour la convolution\n",
    "x_train = x_train.reshape(-1, 32, 32, 3)\n",
    "x_val = x_val.reshape(-1, 32, 32, 3)\n",
    "x_test = x_test.reshape(-1, 32, 32, 3)\n",
    "# Encodage One-Hot des labels\n",
    "y_train_c = to_categorical(y_train, 10)\n",
    "y_val_c = to_categorical(y_val, 10)\n",
    "y_test_c = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be68492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN classique (comme dans le TD)\n",
    "model = Sequential([\n",
    "Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)), # Couche Conv\n",
    "MaxPooling2D(2,2), # Max Pooling\n",
    "Conv2D(64, (3,3), activation='relu'), # Deuxième Couche Conv\n",
    "MaxPooling2D(2,2),\n",
    "Flatten(), # Aplatit les données\n",
    "Dense(128, activation='relu'), # Couche Fully Connected\n",
    "Dense(10, activation='softmax') # Couche de sortie (10 classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN un peu plus complexe (une couche de convolution en + et ajout de dropout)\n",
    "\n",
    "model_2 = Sequential([\n",
    "Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)), \n",
    "MaxPooling2D(2,2), \n",
    "Dropout(0.25),\n",
    "Conv2D(64, (3,3), activation='relu'), \n",
    "MaxPooling2D(2,2),\n",
    "Dropout(0.25),\n",
    "Conv2D(128, (3,3), activation='relu'),\n",
    "Flatten(),\n",
    "Dense(256, activation='relu'), \n",
    "Dense(10, activation='softmax') \n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modèle basé sur le CDNN https://arxiv.org/pdf/1202.2745v1 \n",
    "\n",
    "\n",
    "model_3 = Sequential([\n",
    "    Conv2D(300, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),  \n",
    "    Conv2D(300, (2, 2), activation='relu'),  \n",
    "    MaxPooling2D((2, 2)), \n",
    "    Conv2D(300, (2, 2), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(300, (2, 2), activation='relu'), \n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(), \n",
    "    Dense(300, activation='relu'),  \n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du 1er model\n",
    "history_1 = model.fit(\n",
    "    x_train, y_train_c,\n",
    "    validation_data=(x_val, y_val_c),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff287c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement model_2\n",
    "history_intermediate = model_2.fit(\n",
    "    x_train, y_train_c,\n",
    "    validation_data=(x_val, y_val_c),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entraînement du CDNN\n",
    "history_deep = model_3.fit(\n",
    "    x_train, y_train_c,\n",
    "    validation_data=(x_val, y_val_c),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plt.plot(history_1.history['loss'], label='Train Loss CNN Simple')\n",
    "plt.plot(history_1.history['val_loss'], label='Validation Loss CNN Simple')\n",
    "plt.plot(history_1.history['accuracy'], label='Train Accuracy CNN Simple')\n",
    "plt.plot(history_1.history['val_accuracy'], label='Validation Accuracy CNN Simple')\n",
    "plt.plot(history_intermediate.history['loss'], label='Train Loss CNN Inter')\n",
    "plt.plot(history_intermediate.history['val_loss'], label='Validation Loss CNN Inter')\n",
    "plt.plot(history_intermediate.history['accuracy'], label='Train Accuracy CNN Inter')\n",
    "plt.plot(history_intermediate.history['val_accuracy'], label='Validation Accuracy CNN Inter')'''\n",
    "plt.plot(history_deep.history['loss'], label='Train Loss CDNN')\n",
    "plt.plot(history_deep.history['val_loss'], label='Validation Loss CDNN')\n",
    "plt.plot(history_deep.history['accuracy'], label='Train Accuracy CDNN')\n",
    "plt.plot(history_deep.history['val_accuracy'], label='Validation Accuracy CDNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
